# 1. 序論



[TOC]



##　　1.1 多項式曲線フィッティング



### 目的🎯

​	<font color='tomato'>新たな入力変数</font>$\hat{x}$ <font color='tomato'>に対して目標変数</font>$\hat{t}$ <font color='tomato'>を予測する関数</font>$y(x)$<font color='tomato'>を求める</font>

### 使用するデータ📈

* 人工的に生成している
  * データ生成の過程がわかっていれば学習したモデルとの比較がしやすいため

#### 訓練集合 $N=10$

* 入力データ集合 $\bf x \rm \equiv (x_1,…,x_N)^T$

  * $[0,1]$区間内で等間隔な$x_n(n=1,...,N)$

* 目標データ集合 $\bf t \rm \equiv (t_1,…,t_N)^T$

  * $\sin(2 \pi x)$の関数値を計算

    → ガウス分布に従う小さなランダムノイズを加えた$t_n$の作成

* 目標データ集合$\bf t$はこれから学習しようとする規則性を保持してるが、

  <u>ノイズ</u>によって不正確になっている

  1. 観測されない信号源の変動の存在によるもの

  　 2. 確率的（統計的：stochastic）なランダムプロセスによるもの

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.2.jpg" alt="Figure1.2." style="zoom:30%"/>
  <p>
    Fig 1.2 円はN=10個の訓練データ集合，曲線はデータの生成に使用した関数sin(2πx)
  </p>
</div>
##### 不確実性

* 与えられた $\hat{x}$ に対する$\hat{y}$には不確実性(uncertainty)がある
  * 有限個のデータ集合から汎化しなければならない

    → 本質的に難しい問題

  * 観測データにノイズが乗っている

　　　　　　　　　　⇓

* 確率論において、厳密かつ定量的に表現する枠組みを与える
* 決定理論において、上記を利用して適切な基準の下で最適な予測をすることを可能にする



### 線形モデル

**<font color="DeepPink">線形モデル (linear model)</font>**

* パラメータに関して線形であるような関数
* 非常に重要な性質を持つ

以下のような多項式を使って**曲線フィッティング(curve fitting)**を行う
$$
y(x,{\bf w})=w_0 + w_1x + w_2x^2 + … + w_Mx^M = \sum_{j=0}^{M}w_{j}x^j  \tag{1.1}
$$

- ${M}$次の$x$に関する式
- ​         ${M}$：多項式の<font color='DeepPink'>**次数(order)**</font>
- ​         $\bf w$：多項式の係数 $w_0, w_1, w_2,…,w_M$ をまとめたベクトル
- $$y(x,\bf w \rm )$$：$x$ の非線形関数かつ係数$\bf w$ の線形関数



### 誤差関数

**<font color="DeepPink">誤差関数(error function)</font>**

* $\bf w$を任意に固定したときの関数$y(x,\bf w \rm)$の値と、訓練集合のデータ点との間のずれを測る関数

* 最小化を行うことで多項式の係数$\bf w$が求まる

#### 二乗和誤差(sum-of-squares error)

* 単純で広く用いられている

$$
E(\bf w \rm)=\frac{1}{2}\sum_{n=1}^{N}\{y(X_n,\bf w \rm)-t_n\}^2  \tag{1.2}
$$
$$
\begin{align}
\sum_{n=1}^{N}\{y(X_n,\bf w \rm)-t_n\}^2 = \{y(x_1,\bf w \rm) – t_1 \}^2 +  \{y(x_2,\bf w \rm) – t_2 \}^2 + \\
\cdots +  \{y(x_n,\bf w \rm) – t_n \}^2
\end{align}
$$

⚠️ 非負($0$と正の整数)であり$0$になるのは、$y(x,\bf w \rm )$が全訓練データ点をちょうど通るときに限る

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.3.jpg" alt="Figure1.3." style="zoom:30%"/>
  <div>
    Fig 1.3 二乗誤差関数の幾何的な解釈
  </div>
</div>

$E(\bf w \rm)$は、各データ点の関数$y(x,\bf w \rm )$ からのずれの二乗の和（の半分）に対応する

- $E(\bf w \rm)$をできるだけ小さくする$\bf w$を選ぶ

- $E(\bf w \rm)$は係数$\bf w$の$2$次関数だから、$2$次の係数に関する微分は$\bf w$の要素に関して線形になり、$E(\bf w \rm)$を最小にするただ1つの解を持つ

  → 解は$\bf w^\star$、得られる多項式は $y(x,\bf w^\star \rm )$ と表す

  





### モデル比較(model comparison) / モデル選択(model selection)

<font color='DeepPink'>**モデル比較(model comparison)**</font> / **<font color='DeepPink'>モデル選択(model selection)</font>**

* 多項式の次数$M$を選択する問題

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.4a.jpg" alt="Figure1.4a." style="zoom:30%"/>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.4b.jpg" alt="Figure1.4b." style="zoom:30%"/>
  <br>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.4c.jpg" alt="Figure1.4c." style="zoom:30%"/>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.4d.jpg" alt="Figure1.4d." style="zoom:30%"/>
  <div>
    Fig 1.4 様々な次数Ｍを持つ曲線のプロット
  </div>
</div>

* $M=0$

  → $y(x,\bf w \rm )=w_0$（定数）

  * データの当てはまりがあまりよくない

* $M=1$

  → $y(x,\bf w \rm )=w_0 + w_1x$（1次）

  * データの当てはまりがあまりよくない

* $M=3$

  → $y(x,\bf w \rm )=w_0 + w_1x + w_2x^2 + w_3x^3$（3次）

  * Fig 1.4の中では$\sin(2\pi x)$に最もよく当てはまっているように見える

* $M=9$

  → $y(x,\bf w \rm )=w_0 + w_1x + … + w_9x^9$（9次）
  * 訓練データには非常によく当てはまっている

  * 全データを完全に通っており$E(\bf w \rm^\star) =0$になっているが、

    あてはめた曲線は $\sin(2\pi x)$ の表現としては明らかに不適切

    → **<font color="DeepPink"><u>過学習(over-fitting)</u></font>**

    　 　規則を作るために与えられたデータに合わせすぎた規則を得てしまうこと



### 評価

* 新たなデータに対して正確な予測を行える高い汎化性能を達成するために、

  汎化性能が$M$にどう依存するかを定量的に評価

#### テスト集合 $N=100$

* 訓練集合と全く同じく、関数値にランダムなノイズを加える方法で生成
  * ランダムなノイズの値は新しく選ぶ

#### 平均二乗平方根誤差(root-mean-square error, RMS error)

* テスト集合において$E(\bf w\rm^\star)$を評価
* テスト集合の誤差は新たな$x$を観測したときに$t$をどれだけよく予測できたかを表す

$$
E_{RMS}=\sqrt{2E(\bf w^\star \rm)/N} \tag{1.3}
$$

📝 最小二乗誤差の値を ①$2$倍して ②$N$で割って ③平方根をとる

- $N$で割る        → サイズの異なるデータ集合を比較できる
- 平方根をとる → $E_{RMS}$は目的変数$t$と同じ尺度（単位）であることが保証される

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.5.jpg" alt="Figure1.5." style="zoom:30%"/>
  <div>
    Fig 1.5 様々なＭに対して、(1.3)で定義した平均二乗平方根誤差
  </div>
</div>

* $0\leq M<3$

  * テスト集合の誤差がかなり大きい
  * $\sin(2\pi x)$の振動を捉えることができない

* $3 \leq M \leq 8$

  * テスト集合の誤差は小さい
  * $\sin(2\pi x)$を生成する妥当な表現

* $M = 9$

  * 訓練集合の誤差は$0$

    * $10$個の係数$w_0,...,w_9$に対応して多項式の自由度が$10$となり、

      訓練集合の$10$個のデータ点にちょうどあてはめられるから

  * $y(x, \bf w^\star \rm)$の無茶苦茶な発振が起きるので、テスト集合の誤差は非常に大きい



* $M=9$次多項式は$M=3$ 次多項式と同程度以上の結果を出すことができるはず
* 新たなデータに対する最良な予測関数はデータを生成した関数$\sin(2\pi x)$だと考えられる

→ $M$を増やせば増やすほど単調に良い結果が得られるだろうと期待する

|             |  $M=0$ |   $M=1$ |    $M=3$ |         $M=9$ |
| :---------: | -----: | ------: | -------: | ------------: |
| $w^\star_0$ | $0.19$ |  $0.82$ |   $0.31$ |        $0.35$ |
| $w^\star_1$ |        | $-1.27$ |   $7.99$ |      $232.37$ |
| $w^\star_2$ |        |         | $-25.43$ |    $-5321.83$ |
| $w^\star_3$ |        |         |  $17.37$ |    $48568.31$ |
| $w^\star_4$ |        |         |          |  $-231639.30$ |
| $w^\star_5$ |        |         |          |   $640042.26$ |
| $w^\star_6$ |        |         |          | $-1061800.52$ |
| $w^\star_7$ |        |         |          |   $102400.18$ |
| $w^\star_8$ |        |         |          |  $-557682.99$ |
| $w^\star_9$ |        |         |          |   $125201.43$ |

<div style='text-align:center;'>
	Table 1.1 様々な次数の多項式について得られたw*の値
</div>

* $M$ の増加に伴い、係数の多くが大きな値をとる
* $M=9$次
  * 多項式が各データ点にぴったり適合するように係数の値を非常に大きな正負の値で調整
  * データ点とデータ点の間では（特に両端の近く）大きな振幅を示す
* $M$が大きく自由度の高い多項式は目的地のランダムノイズに引きずられてしまう



### 過学習解決法

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.6a.jpg" alt="Figure1.6a" style="zoom:30%"/>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.6b.jpg" alt="Figure1.6b" style="zoom:30%"/>
  <div>
    Fig 1.6 M=9次多項式をN=15, N=100のデータ点に対して最小二乗法であてはめた結果
  </div>
</div>
#### データ集合のサイズ$N$を大きくする

* より複雑で柔軟なモデルをデータにあてはめられる
* データ点の数はモデル中の適応パラメータの数の何倍かより小さくてはいけない
* 必ずしもパラメータの数がモデルの複雑さを測る最適な尺度ではない
* 最小二乗でモデルのパラメータを求めるアプローチが**<font color='DeepPink'>最尤推定(maximum likelihood)</font>** の特別な場合に相当し、過学習の問題が最尤推定の持つ一般的性質である



#### <font color='DeepPink'>ベイズ的(Bayesian)</font>アプローチの採用

* モデルのパラメータ数がデータ点の数をはるかに超えても問題ない
* **<font color='DeepPink'>有効パラメータ数(effective number of parameters)</font>**は自動的にデータ集合のサイズに適合



#### <font color='DeepPink'>正則化(regularization)</font>

* 誤差関数$E(\bf w\rm)$に**罰金(penalty)**項を付加することで係数が大きな値になることを防ぐ

* 罰金項のうち最も単純なものは係数を二乗して和をとったもの
  $$
  \widetilde E(\bf w \rm)=\frac{1}{2}\sum_{n=1}^{N}\{y(X_n,\bf w \rm)-t_n\}^2 + \frac{\lambda}{2}||w||^2 \tag{1.4}
  $$

  *   　$||w||^2\equiv \bf w \rm^T \bf w \rm = w^2_0+w^2_1+…+w^2_M$
  *   　　　$\lambda$：正則化項(第2項)と二乗誤差の和の項(第1項)との相対的な重要度を調整
  *   係数$w_0$：正則化から外すことも多い
      *   目的変数の原点の選び方に依存しているから
      *   正則化に入れる場合、専用の正則化係数を掛ける

##### <font color='DeepPink'>縮小推定</font>

* 誤差関数を最小にする解は完全に閉じた形
* 係数の値を小さくする手法
* **<font color='DeepPink'>リッジ回帰(ridge regression)</font>**：$2$次の正則化の場合

* <font color='DeepPink'>**荷重減衰(weight decay)**</font>：ニューラルネットワークの場合



<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.7a.jpg" alt="Figure1.7a" style="zoom:30%"/>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.7b.jpg" alt="Figure1.7b" style="zoom:30%"/>
  <div>
    Fig 1.7　Fig 1.2のデータ集合に対し、正則化を施した誤差関数(1.4)を用いてM=9次の多項式をあてはめた結果
  </div>
</div>

* $\ln{\lambda}=-18$
  * 過学習が抑制
  * 関数$\sin(2\pi x)$にずっと近い表現が得られる
* $\ln{\lambda}=0$
  * 過学習が抑制されすぎている
  * あてはまりが再び悪くなる
* $\ln \lambda = -\infty$（正則化なし）
  * Fig1.4の右下のグラフ
  * 過学習が抑制されていない
  * あてはまりが悪いまま

|             | $\ln \lambda = -\infty$ | $\ln \lambda = -18$ | $\ln \lambda = 0$ |
| :---------: | ----------------------: | ------------------: | ----------------: |
| $w^\star_0$ |                  $0.35$ |              $0.35$ |            $0.13$ |
| $w^\star_1$ |                $232.37$ |              $4.74$ |           $-0.05$ |
| $w^\star_2$ |              $-5321.83$ |             $-0.77$ |           $-0.06$ |
| $w^\star_3$ |              $48568.31$ |            $-31.97$ |           $-0.05$ |
| $w^\star_4$ |            $-231639.31$ |             $-3.89$ |           $-0.03$ |
| $w^\star_5$ |             $640042.26$ |             $55.28$ |           $-0.02$ |
| $w^\star_6$ |           $-1061800.52$ |             $41.32$ |           $-0.01$ |
| $w^\star_7$ |            $1042400.18$ |            $-45.95$ |           $-0.00$ |
| $w^\star_8$ |            $-557682.99$ |            $-91.53$ |            $0.00$ |
| $w^\star_9$ |             $125201.43$ |             $72.68$ |            $0.01$ |

<div style='text-align:center;'>
	Table1.2　いろいろな値の正則化パラメータλをあてはめたM=9次多項式の係数w*
</div>

* $\lambda$の値を増やすとともに係数は小さな値をとるようになる



<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.8.jpg" alt="Figure1.8" style="zoom:30%"/>
  <div>
    Fig1.8　M=9次多項式について平均二乗平方根誤差(1.3)をlnλに対してとったグラフ
  </div>
</div>

* $\lambda$がモデルの実質的な複雑さを制御し、過学習の度合いを決定している



### モデルの複雑さ

* 誤差関数を最小にする手法で実際の応用問題を解く際

  <u>モデルの複雑さを適切に決める方法</u>を見つけなければならない

  * 得られたデータを係数$\bf w$を決めるために使われる訓練集合

    それとは別の<font color='DeepPink'>**確認用集合**</font>（検証用集合; validation set、<font color='DeepPink'>**ホールドアウト集合; hold-out set**</font>）にわける

    * 貴重な訓練データを無駄にすることが多い





## 1.2 確率論

​	🔑 **不確実性**：計測ノイズやデータ集合のサイズが有限であることにより起こる

* 不確実性に関する定量化と操作に関して一貫した枠組みを与え、パターン認識の基礎の中心を担っている

* 決定理論(1.5節)と組み合わせることにより、

  与えられた情報が不完全で曖昧なものでも、そのすべての情報のもとで最適な予測ができる



### 定義

<u>ある事象の**確率**</u> ：**その事象が起きた回数と全試行回数の比**

* 全試行回数が無限に多くなったときの極限を考える

* 確率は$[0,1]$の区間に入っていなければならない

* 事象の集合が互いに排反で、それらがすべての可能な場合を含んでいれば、

  それらの事象の確率値の総和は$1$にならなければいけない



### 変数

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.10.jpg" alt="Figure1.10" style="zoom:30%"/>
  <div>
    Fig1.10　確率の法則を導出するための、2つの確率変数X,Yからなる一般化した設定
  </div>
</div>

* $X$ ：任意の値$x_i (i=1,…,M)$をとれる確率変数
* $Y$ ：任意の値$y_j (j=1,…,L)$をとれる確率変数
* $N$ ：事例の総数
* $n_{ij}$：$X=x_i$，$Y=y_j$となる試行数
* $c_i$  ：$X$が$x_i$を取る試行数（$Y$の取る値と無関係）
* $r_j$  ：$Y$が$y_i$を取る試行数（$X$の取る値と無関係）



### 同時確率

**<font color='DeepPink'>同時確率</font>**（結合確率; joint probability）

* $p(X=x_i,Y=y_i)$：$X$が$x_i,$ $Y$が$y_j$をとる確率

$$
p(X=x_i,Y=y_j)=\frac{n_{ij}}{N} \tag{1.5}
$$

​	📝 $i,j$という枠内の中にある点の数$n_{ij}$を点の総数$N$で割った数



### 周辺確率(marginal probability)

**<font color='DeepPink'>周辺確率(marginal probabikity)</font>**

* $p(X=x_i)$：$X$が$x_i$を取る確率
* 他の変数についての周辺化、すなわち（この場合$Y$についての）足し合わせ

$$
p(X=x_i)=\frac{c_i}{N} \tag{1.6}
$$

​	📝 $i$ 列にある点の数$c_i$を点の総数$N$で割る

#### 確率の加法定理

​	$i$列の事例数は、その列にある枠内の事例数の総和だから$c_i = \sum_j n_{ij}$であり、$(1.5), (1.6)$より
$$
p(X=x_i)=\sum_{j=1}^{L}p(X=x_i,Y=y_j) \tag{1.7}
$$



### 条件付き確率

**<font color='DeepPink'>条件付き確率(conditional probability)</font>**

* $p(Y=y_j|X=x_i)$：$X=x_i$の事例の中での$Y=y_j$の事例の比率

$$
p(Y=y_j | X=x_i)=\frac{n_{ij}}{c_i} \tag{1.8}
$$

​	📝 $i,j$の枠内にある点の数$n_{ij}$を$i$列の点の数で割る

#### 確率の乗法定理

$(1.5), (1.6), (1.8)$から次の関数を得る
$$
\begin{align} 
p(X=x_i, Y=y_j)&=\frac{n_{ij}}{N}=\frac{n_{ij}}{c_i}.\frac{c_i}{N}\\ 
&=p(Y=y_j | X=x_i)p(X=x_i) \tag{1.9} 
\end{align}
$$



### 確率の基本法則

* $p(X,Y)$は同時確率で「$X$かつ$Y$の確率」
* $p(Y|X)$は条件付き確率で「$X$が与えられた下での$Y$の確率」
* $p(X)$は周辺確率で「$X$の確率」

#### <font color='DeepPink'>加法定理(sum rule)</font>

$$
p(X)=\sum_{Y}p(X,Y) \tag{1.10}
$$

#### <font color='DeepPink'>乗法定理(product rule)</font>

$$
p(X,Y)=p(Y|X)p(X) \tag{1.11}
$$



### ベイズの定理

**<font color='DeepPink'>ベイズの定理</font>**
$$
p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)} \tag{1.12}
$$

* $p(X)$
  $$
  p(X)=\sum_{Y}p(X|Y)p(Y) \tag{1.13}
  $$
  

  * 加法定理を使って、分子に現れる量を使って表せられる
  * $(1.12)$の$p(X|Y)$をにおいて、全ての$Y$についての和が$1$になることを保証するための規格化（正規化）定数

###  独立

**<font color='DeepPink'>独立(independent)</font>**

* $p(X,Y) = p(X)p(Y)$
* 乗法定理から$p(Y|X)=p(Y)$であることがわかり、$X$が与えられた下での$Y$の条件付き確率は実際に$X$の値に独立になる



### ヒストグラム

​	 ある確率分布から生成した有限個の点だけが与えられたとき、もとの確率分布をモデル化する方法



<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.11a.jpg" alt="Figure1.11a" style="zoom:30%"/>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.11b.jpg" alt="Figure1.11b" style="zoom:30%"/>
  <br>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.11c.jpg" alt="Figure1.11c" style="zoom:30%"/>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.11d.jpg" alt="Figure1.11d" style="zoom:30%"/>
  <div>
    Fig1.11　9つの値を取りうる変数Xと2つの値を取り得るYの2変数に対する分布
  </div>
</div>

* 左上：同時分布から生成した$N=60$個のサンプルデータ点のプロット
* 右上：$Y$の$2$つの値に対するデータ点の比率のヒストグラム

  * 確率の定義から、これらの比は$N\to \infty$の極限で対応する確率値$p(Y)$に一致

* 左下：$p(X)$に対応するヒストグラム推定
* 右下：$p(X|Y=1)$に対応するヒストグラム推定



### 例

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.9.jpg" alt="Figure1.9" style="zoom:30%"/>
  <div>
    Fig1.9　例：果物が入った2つの色付きの箱
  </div>
</div>

- 赤の箱
  - りんご2個、オレンジ6個
- 青の箱
  - りんご3個、オレンジ1個
- 試行（多数繰り返す）
  - 箱の1つをランダムに選ぶ
    - 赤の箱$40\%$
    - 青の箱$60\%$
  - 果物をランダムに1個取り出す
    - 分け隔てなく同じ確からしさで選ぶ
  - どの果物だったかを記録して元の箱に戻す

#### 変数

- 確率変数$B$：どの箱を選ぶか
  - $r$：赤い箱
  - $b$：青い箱
- 確率変数$F$：どの果物を選ぶか
  - $a$：りんご
  - $o$：オレンジ

#### 確率

* 箱を選ぶ確率
  $$
  p(B=r)=4/10 \tag{1.14}
  $$

  $$
  p(B=b)=6/10 \tag{1.15}
  $$

  ⚠️ $p(B=r) + p(B=b) = 1$ 

* 箱の種類が与えられた下での、果物の条件付き確率
  $$
  p(F=a | B=r) = 1/4 \tag{1.16}
  $$

  $$
  p(F=o | B=r) = 3/4 \tag{1.17}
  $$

  $$
  p(F=a | B=b) = 3/4 \tag{1.18}
  $$

  $$
  p(F=o | B=r) = 1/4 \tag{1.19}
  $$

  ⚠️ これらの確率も規格化されており、以下が成り立つ
  $$
  p(F=a | B=r) + p(F=o | B=r) = 1 \tag{1.20}
  $$

  $$
  p(F=a | B=b) + p(F=o | B=b) = 1 \tag{1.21}
  $$

* 果物（りんご）を選ぶ確率
  $$
  \begin{align} 
  p(F=a) &=  p(F=a|B=r)p(B=r) + p(F=a|B=b)p(B=b) \\ 
  &= \frac{1}{4} \times \frac{4}{10} + \frac{3}{4} \times \frac{6}{10} = \frac{11}{20}    \tag{1.22} 
  \end{align}
  $$
  加法定理より、オレンジを選ぶ確率は $p(F=o) = 1-11/20 = 9/20$

* 果物の種類が与えられた下での、箱の条件付き確率
  $$
  \begin{align} 
  p(B=r|F=o) &=  \frac{p(F=o|B=r)p(B=r)}{p(F=o)} \\ 
  &= \frac{3}{4} \times \frac{4}{10} \times \frac{20}{9} = \frac{2}{3}    \tag{1.23} 
  \end{align}
  $$
  加法定理より、$p(B=b | F=o) = 1-2/3 = 1/3$



#### 事前確率

**<font color='DeepPink'>事前確率(prior probability)</font>**：条件付き確率が判明しない状態で計算する確率

* 例：ただ箱を選ぶ確率

#### 事後確率

**<font color='DeepPink'>事後確率(posterior probability)</font>**：ベイズの定理で条件付き確率から逆算された確率

* 例：果物がわかった後の箱の確率





### 1.2.1 確率密度

* $p(x) \delta x$：実数値をとる変数$x$が区間$(x, x+\delta x(\delta x \to 0))$に入る確率
* $p(x)$：<font color='DeepPink'>**確率密度(probability density)**</font>

$$
p(x \in (a,b)) = \int_a^bp(x)dx \tag{1.24}
$$

* $p(x \in (a,b))$： $x$が区間$(a,b)$に存在する確率

#### <font color='tomato'>条件</font>

$$
p(x) \geq 0 \tag{1.25}
$$

* 確率は負の値であってはいけない

$$
\int_\infty^\infty p(x)dx = 1 \tag{1.26}
$$

* $p(x)$の総和は$1$である
* $x$は実数上のどこかの値をとらなければいけない



#### 変数変換

変数に非線形な変換を施すと、確率密度はヤコビ行列により変換される
$$
\begin{align} 
 p_y(y) &= p_x(x)|\frac{dx}{dy}| \\ 
&= p_x(g(y))|g'(y)| \tag{1.27} 
\end{align}
$$
確率密度の最大値は変数の選び方に依存する



#### 累積分布関数(cumulative distribution function)

$$
P(z) = \int_{-\infty}^zp(x)dx \tag{1.28}
$$

* $x$が区間$(-\infty, z)$に入る確率
  * $-\infty$から$z$までを累積した確率

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.12.jpg" alt="Figure1.12" style="zoom:30%"/>
  <div>
    Fig1.12　確率密度p(x)と累積分布確率P(x)
  </div>
</div>

* 離散変数$(\delta x)$の確率は連続変数$x$上の確率密度$p(x)$に拡張できる
* $x$が区間$(x, x+\delta x(\delta x \to 0))$に入る確率は$p(x)\delta x$で与えられる
* 確率密度は累積分布関数$P(x)$の微分で表現できる



#### 同時分布

* ベクトル$\bf x$→ $x_1,...,x_D$のとき、$p(x) = p(x_1,...,p_D)$と定義できる
* $p({\bf x})\delta x$：$\bf x$が$\bf x$を含む無限小の体積要素$\delta \bf x$に入る確率
* 離散変数と連続変数が組み合わせになっている場合も考えられる

##### 条件

$$
P(\boldsymbol{X}) \geq 0 \tag{1.29}
$$


$$
\int P(\boldsymbol{X})dx = 1 \tag{1.30}
$$

* 積分は$\bf x$の定義域全体にわたって取る

##### 確率質量関数(probability mass function)

​	$x$が離散変数の場合に呼ばれることもある



#### 確率の加法・乗法定理、ベイズの定理

* $x,y$：実変数
* 各連続変数を幅$\Delta$の区間に分けて。その上の離散確率分布を考える

##### 確率の加法定理

$$
P(x) = \int P(x,y)dy \tag{1.31}
$$

* $\Delta \to 0$の極限を取ると、和は積分になる

##### 確率の乗法定理

$$
P(x,y) = p(y|x)p(x) \tag{1.32}
$$





### 1.2.2 期待値と分散

​	⚠️ 最も重要な操作の1つは関数の重み付きの平均を求めること

#### 期待値(expectation)

​	$\mathbb{E}[f]$：ある関数$f(x)$の確率分布$p(x)$の下での平均値

##### 離散分布の場合

* 平均は$x$の取る値ごとに確率値で重み付けられる

$$
\mathbb{E}[f] = \sum_xp(x)f(x) \tag{1.33}
$$

##### 連続変数の場合

* 対応する確率密度に関する積分で表される

$$
\mathbb{E}[f] = \int p(x)f(x)dx \tag{1.34}
$$

どちらの場合も、期待値は有限個$N$点での有限和で近似できる
$$
\mathbb{E}[f] \simeq \frac{1}{N}\sum_{n=1}^Nf(x_n) \tag{1.35}
$$

* $\simeq$：近似

##### 多変数関数の期待値を考える場合

​	どの変数について平均を取るかを示す（この場合は$x$）
$$
\mathbb{E}_x [f(x,y)] \tag{1.36}
$$

* 関数$f(x,y)$の$x$の分布に関する平均
* $\mathbb{E} [f(x,y)]$は$y$の関数になる



#### 条件付き期待値(conditional expectation)

​	条件付き分布についても同じように考えられる
$$
\mathbb{E}_x[f|y]=\sum_xp(x|y)f(x) \tag{1.37}
$$

#### 分散

​	$var[f]$：$f(x)$がその平均値$\mathbb{E}[f(x)]$の周りでどれぐらいばらつくかの尺度
$$
var[f] = \mathbb{E}\bigl[(f(x)-\mathbb{E}[f(x)])^2\bigr] \tag{1.38}
$$

* 2乗を展開すると

$$
var[f] = \mathbb{E}[f(x)^2]-\mathbb{E}[f(x)]^2 \tag{1.39}
$$

* 確率変数$x$自身の分散を考えると

$$
var[x] = \mathbb{E}[x^2]-\mathbb{E}[x]^2 \tag{1.40}
$$



#### 共分散(covariance)

​	$x$と$y$が同時に変動する度合い

* $x$と$y$が独立なら$cov[x,y]=0$

$$
\begin{align} 
cov[x,y] &= \mathbb{E}_{x,y} [\{x-\mathbb{E}[x]\}\{y-\mathbb{E}[y]\}] \\ 
&= \mathbb{E}_{x,y}[xy]-\mathbb{E}[x]\mathbb{E}[y] \tag{1.41} \\ 
\end{align}
$$

##### $2$つの確率変数ベクトル$\boldsymbol{x,y}$

$$
\begin{align} 
cov[\boldsymbol{x,y}] &= \mathbb{E}^{x,y} [\{\boldsymbol{x}-\mathbb{E}[\boldsymbol{x}]\}\{\boldsymbol{y}^T-\mathbb{E}[\boldsymbol{y}^T]\}] \\ 
&= \mathbb{E}_{x,y}[\boldsymbol{xy}^T]-\mathbb{E}[\boldsymbol{x}]\mathbb{E}[\boldsymbol{y}^T] \tag{1.42} \\ 
\end{align}
$$

* ベクトル$\bf x$の成分間の共分散

  ​	$cov[\bf x \rm] \equiv cov[\bf x\rm, \bf x \rm]$





### 1.2.3 ベイズ確率

#### 確率解釈

##### **<font color='DeepPink'>古典的確率(classical probability)</font>**あるいは**<font color='DeepPink'>頻度主義的(frequentist)</font>**

* 確率をランダムな繰り返し試行の頻度とみなす解釈
* ${\bf w}$
  * 固定したパラメータ
  * 何らかの推定量
* 推定の誤差範囲はデータ集合$\mathcal{D}$の分布を考慮して得られる
* 広く最尤推定が用いられている
* 誤差範囲を決めるアプローチとしてブートストラップ(bootstrap)が用いられている



##### **<font color='DeepPink'>ベイズ的(Bayesian)</font>**

* 不確実性を定量的に表現し、新たな証拠に照らして正しく修正する。

   結果として最適な行動や決定を下す解釈

* 実際観測されたデータ集合$\mathcal{D}$があり、パラメータに関する不確実性は${\bf w}$の確率分布として表される

* **利点**

  * 事前知識を自然に入れられること

* **批判**

  * 事前分布が数学的な便宜によって選ばれることが多い
  * 選び方によって結果が主観的になることもある
  * <font color='deeppink'>無情報事前分布(noninformative prior)</font>を使うと異なるモデルを比較する際に困難が生じる
  * 悪い事前分布を選べば、高い確率で悪い結果が得られる

* **解決法**

  * 頻度主義的な評価方法を用いる
  * 交差確認といったテクニックがモデルの選択などの問題には有効である

###### ベイズの定理

​	$\mathcal{D}$を観測した事後に$\bf w$に関する不確実性を事後分布$p({\bf w}|\mathcal{D})$で評価する
$$
p({\bf w} | \mathcal{D})=\frac{p(\mathcal{D} | {\bf w})p({\bf w})}{p(\mathcal{D}) } \tag{1.43}
$$

* $\mathcal{D}$：観測データ$\mathcal{D} = {t_1,...,t_N} $
* $\bf w$：パラメータ
* $p(\bf w\rm)$​：事前確率分布
  * データを観測する前にあらかじめ$\bf w$に関する仮設を立てる
* $p(\bf w\rm|\mathcal{D})$：事後分布

- $p(\mathcal{D}|\bf w\rm)$：**<font color='DeepPink'>尤度関数(likehood function)</font>**

  - データ集合$\mathcal{D}$に対する評価であり、パラメータベクトル$\bf w$の関数

  - パラメータベクトル$\bf w$ を固定したときに、観測されたデータ集合がどれぐらい起こりやすいか


* $p(\mathcal{D})$：規格化定数

  * 積分すると$1$になることを保証する
  * 事前分布と尤度関数で表すことができる

  $$
  p(\mathcal{D})=\int p(\mathcal{D} | \boldsymbol{w})p(\boldsymbol{w})d\boldsymbol{w} \tag{1.45}
  $$

  

​	尤度の定義から、ベイズの定理を言葉で表すと
$$
事後確率 \propto 尤度 \times 事前確率 \tag{1.44}
$$

* $\propto$：比例する
* 事後確率は、尤度と事前確率の積に比例する



#### 最尤推定

**<font color='DeepPink'>最尤推定(maximum likehood)</font>**

* ${\bf w}$は<u>尤度関数$p(\mathcal{D}|{\bf w})$を最大にする値</u>
* **<font color='tomato'>観測されたデータ集合の確率を最大にするパラメータ</font>$\mathbf{w}$<font color='tomato'>を選ぶこと</font>**
* 尤度関数の対数の符号を反転したものは<font color='deeppink'>誤差関数(error function)</font>
  
  * 対数のマイナスは単調減少関数だから、尤度の最大化は誤差の最小化と等価
  * <font color='deeppink'>ブートストラップ(bootstrap)</font>
    * もととなるデータ集合${\bf X}$：$\{x_1,...,x_N\}$からランダムにN点を復元抽出した${\bf X}_B$を作る
    * ${\bf X}$のいくつかの点は${\bf X_B}$に複数回出現するが、一方で${\bf X_B}$に入っていない点も存在する
    * パラメータ推定の統計的な精度は異なる${\bf X_B}$に対する予測の変動を見ることで評価できる





### 1.2.4 ガウス分布

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.13.jpg" alt="Figure1.13" style="zoom:30%"/>
  <div>
    Fig1.13　1変数ガウス分布
  </div>
</div>

**<font color='deeppink'>正規分布(normal distribution</font>**または**<font color='deeppink'>ガウス分布</font>**
$$
\mathcal{N}\left(x | \mu, \sigma^{2}\right)=\frac{1}{\left(2 \pi \sigma^{2}\right)^{1 / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right\} \tag{1.46}
$$

* $\mu$：<font color='deeppink'>平均(mean)</font>
* $\sigma^2$：<font color='deeppink'>分散(variance)</font>
* $\sigma$：<font color='deeppink'>標準偏差(standard deviation)</font>
* $\beta = 1/\sigma^2$：<font color='deeppink'>精度パラメータ(precision parameter)</font>

#### 要件

$$
\mathcal{N}(x | \mu, \sigma^2) > 0 \tag{1.47}
$$

$$
\int_{-\infty}^\infty \mathcal{N}(x | \mu, \sigma^2)dx = 1 \tag{1.48}
$$

$(1.46)$は2つの要件を満たしている



####期待値

$$
\mathbb{E}[x^2] = \int_{-\infty}^\infty \mathcal{N}(x | \mu, \sigma^2) x^2 dx = \mu^2 + \sigma^2 \tag{1.49}
$$

* $\mu$：ガウス分布のもとでの$x$の平均値になる

$$
\mathbb{E} = \int_{-\infty}^\infty \mathcal{N} (x|\mu,\sigma^2) x^2dx = \mu^2 + \sigma^2 \tag{1.50}
$$

$(1.49)$と$(1.50)$より
$$
var[x] = \mathbb{E}[x^2] - \mathbb{E}[x]^2 = \sigma^2 \tag{1.51}
$$

* $\sigma^2$：分散パラメータ
* $x$：モード（最頻値）
  * 平均に一致する



#### D次元ベクトルの連続変数$\mathbf{x}$の場合

$$
\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})=\frac{1}{(2 \pi)^{D / 2}} \frac{1}{|\mathbf{\Sigma}|^{1 / 2}} \exp \left\{-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right\} \tag{1.52}
$$

* $\mu$：平均
* $\sum$：分散
  * $|\sum|$：$\sum$の行列式



#### 最尤推定

* 尤度関数の対数を取る
* $\mu$に関して対数尤度関数を最大化する
* $\sigma^2$に関して対数尤度関数を最大化する

##### 尤度関数

* 未知の平均$\mu$と分散$\sigma^2$を持つガウス分布から独立に生成された観測値があったとき、パラメータをデータ集合から求める
  - **<font color='tomato'>未知のパラメータを決めるために尤度関数を最大化する</font>**

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.14.jpg" alt="Figure1.14" style="zoom:30%"/>
  <div>
    Fig1.14　ガウス分布の尤度関数
  </div>
</div>

* 赤い線：尤度関数
* 黒い点：データ集合$\{x_n\}$
* 青い点：$\{x_n\}$の尤度

$$
p\left(\mathbf{x} | \mu, \sigma^{2}\right)=\prod_{n=1}^{N} \mathcal{N}\left(x_{n} | \mu, \sigma^{2}\right) \tag{1.53}　\\
$$

$$
\mathcal{N}\left(x | \mu, \sigma^{2}\right)=\frac{1}{\left(2 \pi \sigma^{2}\right)^{1 / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right\} \tag{1.46}
$$



* $\mu$と$\sigma^2$が与えられたときのデータ集合の確率
* $\mu$と$\sigma^2$の関数とみなすと、ガウス分布に対する尤度関数
* $\mathbf{x} = [x_1,…x_N]^T$ 
  * <font color='deeppink'>独立同分布(independent identically distribution)</font> = i.i.d
    * データ点が同じ分布から独立に生成されること
* $\mu$, $\sigma^2$：ガウス分布の未知のパラメータ



###### 導出





##### 対数尤度関数

* $f(x) > 0$のとき、$\log f(x)$が$x = x_m$で最大になるならば$f(x)$もまた$x = x_m$で最大になる

$$
\ln p\left(\mathbf{x} | \mu, \sigma^{2}\right)=-\frac{1}{2 \sigma^{2}} \sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}-\frac{N}{2} \ln \sigma^{2}-\frac{N}{2} \ln (2 \pi) \tag{1.54}
$$

###### $\mu$についての最尤推定

$$
\mu_{\mathrm{ML}}=\frac{1}{N} \sum_{n=1}^{N} x_{n} \tag{1.55}
$$

* <font color='deeppink'>サンプル平均(標本平均 ; sample mean)</font>
* 観測値$\{x_n\}$の平均
* $\frac{\delta}{\delta\mu} \log L$が$0$になる最尤推定の値を求める

###### $\sigma^2$についての最尤推定

$$
\sigma_{\mathrm{ML}}^{2}=\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\mu_{\mathrm{ML}}\right)^{2} \tag{1.56}
$$

* <font color='deeppink'>サンプル分散(標本分散 ; sample variance)</font>
* $\frac{\delta}{\delta\sigma^2} \log L$が$0$になる最尤推定の値を求める
* $\mu_{ML}$を代入する



##### バイアス

​	分布の分散が系統的に過小評価されている現象のこと

* 最尤解のバイアスはデータ点の数が増えればあまり重要ではなくなる
  * $N\to\infty$ の極限では分散の最尤解はデータを生成した真の分散に一致する

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.15.jpg" alt="Figure1.15" style="zoom:30%"/>
  <div>
    Fig1.15　ガウス分布の分散の最尤推定で起きるバイアス
  </div>
</div>

* 緑の線：データを生成した真のガウス分布
* 赤い線：各組のデータ集合にあてはめたガウス分布
* 青い点：データ点（各2つ）

###### 期待値

$$
\mathbb{E}\left[\mu_{\mathrm{ML}}\right]=\mu \tag{1.57}
$$

$$
\mathbb{E}\left[\sigma_{\mathrm{ML}}^{2}\right]=\left(\frac{N-1}{N}\right) \sigma^{2} \tag{1.58}
$$

* 真の分散が$N-1/N$倍過小評価されている

###### 分散パラメータの不偏推定量

* **不偏推定量**：平均的には真の値を正しく予測できるような推定量
  $$
  \mathbb{E}[\hat{\theta}] = \theta
  $$

  - $\theta$：真の値
  - $\hat{\theta}$：$\theta$の一致推定量かつ確率変数

* **一致推定量**：サンプル数を増やしていくと確実に真の値を正しく予測できる

$$
\tilde{\sigma}^{2}=\frac{N}{N-1} \sigma_{\mathrm{ML}}^{2}=\frac{1}{N-1} \sum_{n=1}^{N}\left(x_{n}-\mu_{\mathrm{ML}}\right)^{2} \tag{1.59}
$$

* $N/N-1$倍することで過小評価の分が補正される
  * 最尤推定値の分散を真の分布の分散と近似させる



### 1.2.5 曲線フィッティング再訪

#### 目標🎯

* 訓練データ集合の入力値$\mathbf{x} = \{x_1,…,x_N\}^\mathbf{T}$と対応する目標値$\mathbf{t} = \{t_1,…,t_N\}^\mathbf{T}$に基づいて、

  与えられた新たな入力値$x$に対応する目標値$t$の予測ができるようにすること

  

#### 目標変数の値に対する不確実性の確率分布

$$
p(t | x, \mathbf{w}, \beta)=\mathcal{N}\left(t | y(x, \mathbf{w}), \beta^{-1}\right) \tag{1.60}
$$

* 平均が式$(1.1)$で与えられる多項式曲線$y(x, \mathbf{w})$に等しいガウス分布に従う
* $\beta$：精度パラメータ

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.16.jpg" alt="Figure1.16" style="zoom:30%"/>
  <div>
    Fig1.16　式(1.60)の模式図
  </div>
</div>

* 平均：$y(x, \mathbf{w})$で与えられた多項式
* 分散：$\beta^{-1} = \sigma^2$



#### 最尤推定

##### 尤度関数

​	データが式$(1.60)$から独立に取られたものだと仮定すると
$$
p(\mathbf{t} | \mathbf{x}, \mathbf{w}, \beta)=\prod_{n=1}^{N} \mathcal{N}\left(t_{n} | y\left(x_{n}, \mathbf{w}\right), \beta^{-1}\right) \tag{1.61}
$$

* $\{\mathbf{x}, \mathbf{t}\}$：訓練データ
* $\mathbf{w}, \beta$：未知のパラメータ



##### 対数尤度関数

​	式 $\mathcal{N}\left(x | \mu, \sigma^{2}\right)=\frac{1}{\left(2 \pi \sigma^{2}\right)^{1 / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right\}\ (1.46)$ のガウス分布の形を置き換えると
$$
\ln p(\mathbf{t} | \mathbf{x}, \mathbf{w}, \beta)=-\frac{\beta}{2} \sum_{n=1}^{N}\left\{y\left(x_{n}, \mathbf{w}\right)-t_{n}\right\}^{2}+\frac{N}{2} \ln \beta-\frac{N}{2} \ln (2 \pi) \tag{1.62}
$$

###### $\mathbf{w}$についての最尤推定

$$
\mathbf{w}_{ML} = \frac{1}{2}\sum_{n=1}^{N}\{y(x_n,\bf w \rm)-t_n\}^2 = E(\bf w \rm)\ (1.2)
$$

* <font color='deeppink'>二乗和誤差関数(sum-of-squares error)</font>と等価
  * 対数尤度の第2項、第3項は$\mathbf{w}$に依存しないので無視
  * 　　〃　を正の定数倍しても$\mathbf{w}$の値は変わらない → $\beta/2$を$1/2$で置き換える
  * 　　〃　を最大化する代わりに、それと等価な負の対数尤度を最小にできる

　　　　　　　　　　　　　　　　　　　　⇓

​	**<font color='tomato'>二乗和誤差関数はノイズがガウス分布に従う仮定の下での尤度の最大化の結果とみなせる</font>**

###### $\beta$についての最尤推定

$$
\frac{1}{\beta_{\mathrm{ML}}}=\frac{1}{N} \sum_{n=1}^{N}\left\{y\left(x_{n}, \mathbf{w}_{\mathrm{ML}}\right)-t_{n}\right\}^{2} \tag{1.63}
$$

* パラメータベクトル$\mathbf{w}_{ML}$から上の式の平均を求める



#### 予測分布

​	パラメータが決まれば**<font color='deeppink'>予測分布(predictive distribution)</font>**という形で、$x$の新たな値に対する$t$の確率分布を与える
$$
p\left(t | x, \mathbf{w}_{\mathrm{ML}}, \beta_{\mathrm{ML}}\right)=\mathcal{N}\left(t | y\left(x, \mathbf{w}_{\mathrm{ML}}\right), \beta_{\mathrm{ML}}^{-1}\right) \tag{1.64}
$$


#### MAP推定

​	**<font color='deeppink'>最大事後確率推定(maximum posterior)</font>**もしくは**<font color='deeppink'>MAP推定</font>**

* 事後分布を最大化する$\mathbf{w}$を決める

##### 事前分布

$$
p(\mathbf{w} | \alpha)=\mathcal{N}\left(\mathbf{w} | \mathbf{0}, \alpha^{-1} \mathbf{I}\right)=\left(\frac{\alpha}{2 \pi}\right)^{(M+1) / 2} \exp \left\{-\frac{\alpha}{2} \mathbf{w}^{\mathrm{T}} \mathbf{w}\right\} \tag{1.65}
$$

* 多項式の係数$\mathbf{w}$に関する事前分布の導入
* $\alpha$：分布の精度パラメータ → **<font color='deeppink'>超パラメータ(hyperparameter)</font>**
  * モデルパラメータの分布を制御するパラーメータ
* $M+1$：ベクトル$\mathbf{w}$の要素数

##### 事後分布


$$
p(\mathbf{w} | \mathbf{x}, \mathbf{t}, \alpha, \beta) \propto p(\mathbf{t} | \mathbf{x}, \mathbf{w}, \beta) p(\mathbf{w} | \alpha) \tag{1.66}
$$

* $\mathbf{w}$の事後分布は事前分布と尤度関数との積に比例

###### 最大化

​	以下の最小値として与えられる
$$
\frac{\beta}{2} \sum_{n=1}^{N}\left\{y\left(x_{n}, \mathbf{w}\right)-t_{n}\right\}^{2}+\frac{\alpha}{2} \mathbf{w}^{\mathrm{T}} \mathbf{w} \tag{1.67}
$$

* 式 $(1.66)$の対数を符号反転
* 式 $(1.62)$と$(1.65)$を組み合わせる

$$
(1.67) = \frac{1}{2}\sum_{n=1}^{N}\{y(X_n,\bf w \rm)-t_n\}^2 + \frac{\lambda}{2}||w||^2 = \widetilde E(\bf w \rm)\ (1.4)
$$

* $\lambda = \alpha/\beta$；正則化パラメータ



### 1.26 ベイズ曲線フィッティング

* MAP推定
  * $\mathbf{w}$の点推定を行っているだけ
* 完全なベイズアプローチ
  * 確率の加法・乗法定理を矛盾なく適用し、$\mathbf{w}$のすべての値に関して積分する必要がある



#### 予測分布

​	パラメータ$\alpha, \beta$は固定されており、事前にわかっているとする
$$
p(t | x, \mathbf{x}, \mathbf{t})=\int p(t | x, \mathbf{w}) p(\mathbf{w} | \mathbf{x}, \mathbf{t}) \mathrm{d} \mathbf{w} \tag{1.68}
$$

* $p(t|x, \mathbf{w})$：式$(1.60)$で与えられ、$\alpha, \beta$は単純化のため省略
* $p(\mathbf{w}|\mathbf{x}, \mathbf{t})$：パラメータの事後分布、式 $(1.66)$の右辺を規格化


$$
p(t | x, \mathbf{x}, \mathbf{t})=\mathcal{N}\left(t | m(x), s^{2}(x)\right) \tag{1.69}
$$

* 式 $(1.68)$ の積分
* ガウス分布の形で与えられる
* 分散や平均は$x$に依存している

$$
m(x)=\beta \phi(x)^{\mathrm{T}} \mathrm{S} \sum_{n=1}^{N} \phi\left(x_{n}\right) t_{n} \tag{1.70}
$$

* $m(x)$：平均

$$
s^{2}(x)=\beta^{-1}+\phi(x)^{\mathrm{T}} \mathrm{S} \phi(x) \tag{1.71}
$$

* $s^2(x)$：分散
* 第１項
  * $t$の予測値の目標変数のノイズによる不確実性
  * 最尤推定の予測分布$(1.64)$で$\beta_{ML}^{-1}$としたものに対応
* 第２項
  * パラメータ$\mathbf{w}$に対する不確実性

$$
\mathbf{S}^{-1}=\alpha \mathbf{I}+\beta \sum_{n=1}^{N} \phi\left(x_{n}\right) \phi\left(x_{n}\right)^{\mathrm{T}} \tag{1.72}
$$

* $\mathbf{S}$：行列
  * $\mathbf{I}$：単位行列
  * $\phi(x)$：$\phi_{i}(x)=x^{i}(i=0, \dots, M)$

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.17.jpg" alt="Figure1.17" style="zoom:30%"/>
  <div>
    Fig1.17　M=9次多項式を使ったベイズ曲線フィッティングの結果の予測分布
  </div>
</div>

* 赤い線：予測分布の平均
* 赤い領域：平均の周りの$\pm 1$標準偏差の範囲
* $\alpha=5\times10^3, \beta = 11.1$





## 1.3 モデル選択

### パラメータの値を決める目的

* 新たなデータに対して最も良い予測をすること
* 与えられたモデル内の複雑さパラメータの適切な値を決める
* 異なる型のモデルも考慮して、それぞれの応用ごとに最も良いモデルを見つけたい



### アプローチ

#### 手持ちのデータの一部を使っていろいろなモデルを学習する

* 1つのモデルの複雑さパラメータの値を変えるかした後、<u>独立なデータ</u>でそれらを比較し最も予測性能の良いものを選ぶ
  * **<font color='deeppink'>確認用集合(検証用集合; validation data)</font>**
* 限られたサイズのデータ集合を使ってモデルの設計を何度も繰り返すと確認用集合においても過学習してしまう
  * 3番目の**<font color='deeppink'>テスト集合(test data)</font>**を別に用意して、選んだモデルの性能を最終的に評価する

#### 交差確認

<div style='text-align:center;'>
  <img src="/Users/marie/NAIST/PRML/prmlfigs-jpg/Figure1.18.jpg" alt="Figure1.18" style="zoom:30%"/>
  <div>
    Fig1.18　S=4の場合のS重交差確認法
  </div>
</div>

* 赤のブロック：ホールドアウトグループ

**<font color='deeppink'>交差確認(交差検証; cross validation)</font>**

* 得られたデータの$(S-1)/S$の割合部分を訓練に使いつつ、全データを性能の評価に使うことができる
  * 得られたデータを$S$個のグループにわける
  * $S-1$個のグループがモデル集合の訓練に使われ、残ったグループで評価を行う
  * 以上の手順を$S$個のホールドアウトグループの選び方に関して繰り返し、$S$回の性能のスコアを平均する
* <font color='deeppink'>LOO法(1個抜き法; leave-one-out method)</font>
  * データ数が特に少ないとき、データ点数を$N$としたときに$S=N$と考える
* 欠点
  * 訓練を行わなければいけない回数が$S$に比例して大きくなる
  * 最悪の場合、パラメータの数に対して指数関数的に訓練回数が増える可能性がある

#### 情報量基準(information criterion)

* より複雑なモデルによる過学習を避ける罰金項を足すことで最尤推定のバイアスを修正する
* モデルパラメータの不確実性は考慮しておらず、実際には過度に単純なモデルを選ぶ傾向にある

##### **<font color='deeppink'>赤池情報量基準(Akaike information criterion)</font>**もしくはAIC

​	以下が最大になるモデルを決める
$$
\ln p\left(\mathcal{D} | \mathbf{w}_{\mathrm{ML}}\right)-M \tag{1.73}
$$

* $p\left(\mathcal{D} | \mathbf{w}_{\mathrm{ML}}\right)$：最尤推定を行った場合の対数尤度
* $M$：モデルの中の可変パラメータ数

##### **<font color='deeppink'>ベイズ情報量基準(Bayesian information criterion)</font>**もしくは**<font color='deeppink'>BIC</font>**



## 1.4 次元の呪い



## 1.5 決定理論

* 不確かさを含む状況における最適な意思決定を行うことを可能にする